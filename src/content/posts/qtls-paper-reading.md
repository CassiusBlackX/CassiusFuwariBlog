---
title: qtls-paper-reading
published: 2026-01-24
description: '论文QTLS: High-Performance TLS asynchronous offload framework'
image: ''
tags: []
category: ''
draft: false 
lang: ''
---
# abstract
直接卸载TLS加解密操作会因为IO中频繁出现长时间阻塞而造成CPU和加速器资源的利用率不足。

基于QAT，提出高性能TLS异步卸载框架：QTLS。QTLS对TLS软件栈进行重新涉及，将TLS卸载分为四个阶段以消除阻塞。这样一来，同一进程/线程中可同时卸载来自不同TLS连接的多个加解密操作，从而显著提升性能。此外，QTLS采用一种启发式轮询方案，以高效、及时地获取加速器的相应；还引入了一种内核旁路通知机制，避免了用户态与内核态之间昂贵的切换，同时实现了异步事件的传递。

QTLS在RSA2048的时候，每秒连接数CPS可提升9倍，安全数据传输吞吐量提升2倍，平均响应延迟降低85%。

# introduction
直接卸载TLS涉及到的加解密任，会导致IO频繁，长时间阻塞
+ 大量CPU周期周期用于等待
+ 加速器内部并行计算单元利用率低下。

为消除卸载IO中的阻塞，QTLS对TLS软件栈进行了重新涉及，以在所有层中都实现对加解密操作的异步支持。TLS卸载分为4个阶段：预处理、QAT响应检索、异步事件通知和后处理。
在预处理阶段，加解密任务提交后会暂停卸载任务，将控制权还给应用进程。当检索到QAT对加解密结果的响应时候，应用进程会通过异步事件得到通知，从而恢复暂停的卸载任务并进入后处理阶段。
在该框架中，CPU资源得到了充分利用，以处理并发连接。来自不同TLS连接的多个加解密操作可以在同一个进程/线程中并发卸载，提高QAT加速器内部计算引擎的利用率。为了进一步提升性能，QTLS采用
+ 启发式轮询方案，利用应用级的只是，实现高效且及时的QAT响应检索
+ 内核旁路通知方案，引入应用定义的异步队列，避免用户态和内核态之间昂贵的切换，同时实现异步事件的传递。

# background
## TLS overview
TLS连接分为两个阶段
+ 握手阶段: 确定加解密算法、执行身份验证并协商用于数据解密和消息认证码(MAC)的共享密钥
+ 安全数据传输阶段: 通过已经建立的TLS连接发送加解密数据。

#### handshake
#### secure data transfer
#### resource consumption
#### session resumption
TLS提供了一种名为session resumption的机制(通过session id或session ticket)，可避免每次进行完整握手。但是可能导致前向安全性的保护变弱。

## event-driven web architecture
nginx

## QAT

## challenges with TLS offloading
TLS的直接卸载是用于模式是把和加解密相关的函数调用替换为一个与硬件IO的函数调用。在这个模式下，可以复用现有的TLS软件栈，只有少部分的地方需要做修改。但是，对于事件驱动的web架构而言，这样的直接卸载方式并不足以胜任，也无法达到预期的性能提升。

在基于软件的TLS处理中，与加解密相关的函数调用是同步阻塞的调用，会占用CPU资源进行加解密计算。如果加解密操作尚未完成，TLS库层和应用层都无法继续执行。这种涉及在仅使用CPU架构下运行良好，但在直接卸载的模式下，会导致IO频繁出现长时间阻塞。尽管QAT提供了非阻塞的调用接口，但QAT Engine在一个连接提交了加密请求后，无法将控制权返回给上层。也就是说，他必须等待QATjxsuqi完成请求并生成响应。只有在一个加解密结果完成之后，应用进程才能继续执行以生成下一个加解密请求（而引发下一次阻塞）

对于事件驱动的web架构，卸载IO中的阻塞会导致CPU和QAT资源的利用率不足。首先，大量的CPU周期被用于等待。当加解密请求提交给加速器后，应用程序进程会进入等待状态，从而长时间停止处理事件的循环。其次，QAT加速器内部并行计算引擎的利用率较低。由于第二个加解密请求必须在第一个请求完成后才能提交，因此对于每个应用程序进程，同一时间最多只能使用一个计算引擎。

# QTLS design
## overview
QTLS对QAT Engine, TLS和应用层都做了修改。将TLS卸载分为四个阶段。
+ pre-processing: 当TLS处理程序遇到加解密操作时，在加解密请求提交给QAT加速器后，卸载任务就会立即暂停。应用程序继续处理其它的连接，而不是阻塞住等待QAT的响应。来自不同连接的多个加解密操作可以在一个进程中并发地卸载。
+ QAT response retrieval: 随着越来越多地并发加解密请求被提交，需要即使检索并回收QAT的响应。这里涉及一种启发式轮询方案，以实现高效且即使的检索。
+ async event notification: 每次一个心的QAT响应被回收，都会调用一个已经注册过的回调函数，来产生一个异步事件，以通知应用程序一部加解密请求已完成。在这里涉及了一种内核旁路的通知方案，以避免在传递异步事件时用户态和内核态之间昂贵的切换开销
+ post-processing: 根据捕获的异步事件，响应的TLS连接以及相同的TLS处理器将由应用程序进程重新调度，以恢复暂停的卸载任务。由于加解密计算结果现在已经就绪，因此连接可以进入下一步骤。

在这个框架中，CPU资源可以得到充分利用，以处理并发连接。此外，并发卸载的加解密请求极大提高了QAT加速器内部并行计算引擎的利用率。

## pre-processing and post-processing
卸载IO阻塞的根本原因是，如果加解密操作尚未完成，TLS库层和应用层都无法继续推进。通过在TLS软件栈中引入异步加解密行为，并将卸载IO拆分为pre-processing阶段（异步卸载任务呗暂停）和post-processing阶段（恢复异步卸载任务），从而绕过这一限制。

在TLS库层次，QTLS引入了*crypto pause*和*crypto resumption*。前者是由QAT Engine利用，在提交加解密请求后暂停当前的卸载任务，并以特定错误码返回给上层应用。后者由应用进程利用，用于恢复已暂停的卸载任务以消费加解密结果。卸载任务的暂停与恢复需要对TLS上下文和加解密状态进行细致管理。文章基于OpenSSL开发了两种实现方式。

应用层是异步加解密操作的发起者和完成者。QTLS在应用层维护的TLS状态机中引入了一种名为TLS-ASYNC的新状态。该状态与所有其它可能涉及加解密操作的TLS状态（如握手和TLS-Write）相连。假设当前处理一个握手状态，一旦TLS状态机从TLS库返回的特定错误码中识别处一个暂停的卸载任务，它就会将TLS状态从握手状态更改为TLS-ASYNC。每个暂停的卸载任务都对应一个异步处理程序。此处将其设置为握手处理程序，表明稍后需要重新调度统一处理程序以执行post-processing阶段。此外，应用层负责监控所有暂停的卸载任务，并等待异步事件，以通知加解密请求已完成。

QAT Engine是TLS层与QAT驱动之间的桥梁。一方面，当它使用QAT驱动提供的非阻塞API提交加解密请求时，会注册一个响应回调（用于生成异步事件）；另一方面，提交加解密请求后，它会利用TLS库提供的*crypto pause*，将控制权返回给上层应用

一种特殊情况是加解密提交失败（可能QAT的提交请求环已满）。QTLS通过重用所提出的框架来解决这种这情况。在加解密提交失败后，卸载任务会被暂停。应用程序会通过异步事件或特定返回码以通知此失败。同一TLS处理程序稍后将被重新调度，以恢复暂停的卸载任务并重试加解密提交。

## QAT reponse retrival
QAT响应可通过中断或轮询获取。QTLS利用用户空间IO进行加解密卸载，其中一次基于用户空间的轮询操作比基于内核中断的开销要小得多，所以QTLS选择轮询以实现高吞吐量，尤其在搞负载下。一种边界的轮询方法是为每个应用进程启动一个独立的线程，以定期轮询分配QAT实例，这也是QAT Engine默认采用的方式，但这种方法不可避免的存在一些缺点: 
+ 它引入了应用程序与轮询线程之间的频繁上下文切换
+ 很难确定一个合适的轮询间隔。间隔太小可能导致大量无效的轮询操作， 间隔太大则可能造成较长的延迟，甚至影响吞吐量

为了实现更好的性能并能够很好的适应不同的流量，QTLS设计了一种启发式轮询方案，由于应用程序是加解密请求的生产者，它最了解合适从QAT处回收响应最为合适。该启发式轮询方案集成在应用程序中
+ 避免使用独立的轮询线程
+ 利用应用级知识来指导轮询行为

优势，应用推迟轮询操作以合并足够的响应；然而，另一些时候，可能需要立即执行轮询操作以降低延迟。该启发式轮询方案兼顾了效率与及时性，旨在使响应获取速率始终与请求提交速率保持一致。

#### efficiency
当存在大量TLS连接时，将足够的QAT响应合并为一次轮询操作是合理的。未完成（已提交但是尚未收到响应）的加解密请求数量是一个合适的指标，当该数量达到预定义阈值时，就会触发一次轮询操作。值得注意的是，非对称加解密所需要的事件远长于对称加解密。因此，如果如果还存在未完成的非对称加解密，则会采用更大的阈值

> 为什么不直接把非对称加解密和对称加解密分开处理？？

#### timeliness
在非工作时间，TLS连接较少时，即使轮询非常重要且必要。一个TLS连接可以被识别为以下两种状态
+ 如果它正在处理握手、读取HTTPS请求或向客户端回写HTTPS响应，则该连接出于活动状态
+ 如果它正在等待来自客户端的请求（包括保持连接的情况），则该连接出于空闲状态

在当前设计中，每个活动的TLS连接在同一时刻只能由一个异步加解密请求。因此，一旦未完成的异步加解密请求数量等于活动的TLS连接数量，就需要立即执行一次轮询操作。否则，由于所有活动连接都在等待QAT响应，应用进程可能会陷入阻塞。这种时候，即使轮询就能够大大降低中断客户连接较少时的查询延迟。

## async event notification
对于事件驱动的web架构，异步事件通知的一种自然方式是复用现有的事件驱动方法。具体而言，每次暂停异步卸载任务时，都会为其分配一个文件描述符，并由应用程序的IO多路复用机制与网络套接字一起对其进行监控。当获取到QAT响应时，响应回调函数会在对应的FD上写入一个事件，以通知应用程序。

然而，由于文件描述符由内核维护，这种基于文件描述符的通知机制不可避免地会在用户态和内核态之间引入昂贵的切换。为了避免这种性能开销，我们设计了一种内核旁路通知方案。我们引入了一个由应用程序定义的异步队列，用作监控和通知通道。当TLS状态机识别处一个暂停的卸载任务时，它已经掌握了该任务的async handler信息————实际上，这就是在应用程序接收到异步事件时需要重新调度的TLS处理器。这些信息可以被共享给下层软件栈。随后，当QAT响应被检索到时，响应回调函数只需将对应的async handler插入到异步队列的尾部进行处理。只要存在未完成的加解密请求，著时间循环就会持续执行，而不会进入休眠状态等待IO多路复用机制上的事件。


# implementation
## OpenSSL async crypto support
#### stack async
性能不错，但是对OpenSSl具有侵入性，与现有API不兼容。
#### fiber async
使用fiber，是一个用户空间中协作式的轻量级执行线程，提供了一种基于异步IO自然组织并发代码的方式。通过显式让出和协作式调度，fiber的方案允许一个进程/线程管理多个执行路径，实现异步卸载任务。

当首次调用TLS API的时候（如握手），它会使用`ASYNC_start_job`来启动一个新的基于fiber的`ASYNC_JOB`，以封装TLS连接的运行部分（此处进行fiber ctx切换）。基于fiber的`ASYNC_JOB`可在任意点暂停，将控制权返回主代码，并在稍后恢复执行，直接跳转到暂停点。如果所调用的加密API（如RSA签名）通过`ASYNC_get_current_job`识别出来一个异步卸载任务，则它首先以非阻塞模式提交加解密请求，然后利用`ASYNC_pause_job`将控制权返回（fiber ctx切换）。当再次调用相同的TLS API时，它会使用`ASYNC_start_job`，并将已暂停的`ASYNC_JOB`作为参数，直接跳转（fiber ctx切换）到暂停点并消费加解密结果。

自OpenSSL1.1.0启，（直到OpenSSL3.0系列也仍然）支持。

## nginx modifications for async crypto support
加解密暂停可能发生在一下函数中: `ngx_ssl_handshake`, `ngx_ssl_handle_recv`, `ngx_ssl_write`, `ngx_ssl_shutdown`。这些函数已被修改，以识别OpenSSL中名为`SSL_ERROR_WANT_ASYNC`的心错误代码，该代码表示已提交异步加解密请求。如果收到此新错误代码，则暂停的卸载作业的异步处理程序将设置为当前处理程序。

理想情况下，当异步卸载作业暂停并返回到nginx的时候，此TLS期待的事件类型应该只可能是异步事件，该事件将暂停恢复的作业。但是也存在一种可能，在预期的异步事件之前，存在一个读取事件（来自network socket）。这个读取事件可能是TLS握手过程中的下一条消息，也可能是连接建立后的第一个HTTP请求。这种事件混乱可能导致HTTP或TLS状态机回退到先前的状态。为了解决这个问题，QTLS在预期异步事件时会清楚并保存读取事件的处理程序，并在处理异步事件时将其恢复。

## heuristic polling scheme
对每种加解密操作都维护独立的引用计数。在QAT Engine中，当一个加解密操作相关函数被调用(e.g. `qat_rsa_priv_dec`)时，引用计数加一。获取QAT响应后，对应的引用计数减一。

在nginx中，有一个*stub_status*模块，手机有用的信息，如存活连接数和等待请求的空闲连接数。QTLS在这里添加了对TLS连接的检查，使用公式$TC_{active} = TC_{alive} - TC_{idle}$

当$R_{total}$增加或$T_{active}$减少时，都可以满足timeliness和efficiency的约束。因此，在nginx中，不管是可能要执行一个crypto操作，还是$TC_{active}$可能要被更新，都会要检查约束件并决定是否要执行轮询操作。

对于failover的情况，在nginx中，设置了有计时器，会定期检查是否至少执行了一次轮询操作。如果没有执行过，但存在inflight的请求，那么到时间了就也轮询一次。

## async event notification
#### FD-based notification
QAT Engine用*set-FD API*在加解密暂停前，把fd与async job关联。应用程序再合适的事件使用*get-FD API*获取油管的已添加的FD的信息（需要添加到monitoring中）和已删除的FD信息（需要从monitoring中删除）。通常，每个暂停的卸载作业都应创建一个新的FD。但是考虑到**每个TLS连接在同一时间只能有一个异步卸载作业，**一种优化方法是让同一个异步连接的所有异步作业共享一个FD。

> 非对称加解密的确是这样的，但是在HTTP2中，不是已经支持了多路复用，可以并发发送多个请求吗？
> 在这样的情况下，在一个TLS连接中，不就会存在，上一个加密请求还没有完成的时候，又收到并需要下发下一个加密请求了？
> 那么这个优化方法的前提条件直接就是错的了啊

#### kernel-bypass notification
在应用程序层次，引入了一个回调函数来管理*async queue*。该函数拿着*async handler*的信息作为参数，然后添加到async queue的尾部。在OpenSSL中，两个新的成员`callback`和`callback_arg`添加到了`ASYNC_JOB`结构体中。同时，也新增了一系列的API，供用户设置或获取这些成员。

> 大概了一下OpenSSL3.0，API已经发生了一些变化，在`ASYNC_JOB`中并没有`callback`和`callback_arg`，但是在`async_wait_ctx_st`(即`ASYNC_WAIT_CTX`)中倒是看到了一模一样的成员。

每次TLS状态机识别到暂停的卸载作业时，它都会调用*SSL_set_async_callback API*来设置应用级回调和异步处理程序。当获取到QAT响应时，响应回调函数会利用*ASYNC_WAIT_CTX_get_callback API*检查当前卸载作业是否已设置回调成员。如果是，则可以直接以`callback_arg`（即async handler的信息）作为参数调用应用级回调函数，完成通知。

# evaluation